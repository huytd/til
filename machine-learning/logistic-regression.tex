\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Logistic Regression Problems}
\author{Huy Tr.}
\date{October 3rd, 2016}
\usepackage{amsmath}

\begin{document}

\maketitle

In the previous post, we learned \textbf{Linear Regression} to predict a continuous value as a linear function of input values. Now we take another problem: \textbf{classification}

\section{Classification Problems}

\begin{flushleft}
It's just like the regression problem, except the value \textit{y} now only takes a small number of discrete values.
\end{flushleft}
\begin{flushleft}
For example, with \textbf{binary classification}, the \textit{y} values should only takes 0 (\textbf{negative class}) and 1 (\textbf{positive class}).
\end{flushleft}
\begin{flushleft}
Classification can be found in \textit{spam detection problems}, etc...
\end{flushleft}

\section{Logistic Regression}

\begin{flushleft}
Logistic Regression is the approach to solve classification by ignoring the fact that \textit{y} is discrete-valued and use the old good \textbf{linear regression} algorithm to predict \textit{y} by \textit{x}. But we need to change our \textbf{hypothesis function} $h_{\theta}(x)$:
\end{flushleft}

\begin{equation}
    h_{\theta}(x)=g(\theta^{T}x)=\frac{1}{1 + e^{-\theta^{T}x}}
\end{equation}

Which: 

\begin{equation}
    g(z)=\frac{1}{1 + e^{-z}}
\end{equation}

\begin{flushleft}
This called \textbf{logistic function} or \textbf{sigmoid function}
\end{flushleft}

\begin{flushleft}
Notice that $g(z)$ tends towards 1 as $z\rightarrow\infty$ and towards 0 as $z\rightarrow-\infty$, and $g(z)$ (or $h(x)$ as well) is always bounded between 0 and 1.
\end{flushleft}

\begin{flushleft}
We also have the \textbf{derivative of the sigmoid function} as follow:
\end{flushleft}

\begin{equation}
    g'(z)=\frac{d}{dz}\frac{1}{1 + e^{-z}}=g(z)(1 - g(z))
\end{equation}

\section{How to fit $\theta$ for this logistic regression model?}

\begin{flushleft}
We endow our classification model with a set of probabilistic assumptions then fit the parameters ($\theta$) via \textbf{maximum likelihood}
\end{flushleft}

\begin{flushleft}
Let's assume that:
\end{flushleft}

\begin{equation}
\begin{split}
    P(y=1|\ x;\theta)\ =\ h_{\theta}(x) \\
    P(y=0|\ x;\theta)\ =\ 1 - h_{\theta}(x)
\end{split}
\end{equation}

\begin{flushleft}
Let's rewrite it more compactly:
\end{flushleft}

\begin{equation}
p(y|\ x;\theta)\ =\ (h_{\theta}(x))^{y}(1 - h_{\theta}(x))^{1-y}
\end{equation}

\begin{flushleft}
Assume we have m training examples, the \textbf{likelihood} of the parameters is:
\end{flushleft}

\begin{equation}
\begin{split}
L(\theta)\ &=\ p(\vec{y}\ |\ X;\theta) \\
           &= \prod_{i=1}^m (h_{\theta}(x^{(i)}))^{y^{(i)}}(1 - h_{\theta}(x^{(i)}))^{1-y^{(i)}}
\end{split}
\end{equation}

\begin{flushleft}
And we have the \textbf{log likelihood} $\ell(\theta)$:
\end{flushleft}

\begin{equation}
\begin{split}
\ell(\theta) &= log L(\theta) \\
             &= \sum_{i=1}^m y^{(i)} log h(x^{(i)}) + (1 - y^{(i)}) log (1 - h(x^{(i)}))
\end{split}
\end{equation}

\begin{flushleft}
To maximize the \textbf{likelihood}, we use gradient ascent. We have the \textbf{derivative} for stochastic gradient ascent:
\end{flushleft}

\begin{equation}
\begin{split}
\frac{\partial}{\partial\theta_{j}}\ell(\theta)\ &=\ (y\frac{1}{g(\theta^{T}x)} - (1-y) \frac{1}{1 - g(\theta^{T}x}) \frac{\partial}{\parial\theta_{j}}\ g(\theta^{T}x) \\
    &= (y - h_{\theta}(x))x_{j}
\end{split}
\end{equation}

\begin{flushleft}
So we have the stochastic gradient ascent rule as follow:
\end{flushleft}

\begin{equation}
\theta_{j} = \theta_{j} + \alpha (y^{(i)} - h_{\theta}(x^{(i)}))x^{(i)}_{j}
\end{equation}

\begin{flushleft}
\textbf{Note:} This may looks similar to LMS update rule, but this is not the same algorithm, because $h_{\theta}(x^{(i)})$ now defined as a \textbf{non-linear function} of $\theta^{T}x$
\end{flushleft}

\end{document}
